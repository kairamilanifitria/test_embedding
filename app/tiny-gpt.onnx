from transformers import AutoModelForCausalLM
import torch

model = AutoModelForCausalLM.from_pretrained("sshleifer/tiny-gpt2")
model.eval()

dummy_input = torch.randint(0, 50257, (1, 1))  # GPT-2 vocab size
torch.onnx.export(
    model,
    (dummy_input,),
    "tiny-gpt2.onnx",
    input_names=["input_ids"],
    output_names=["logits"],
    opset_version=13
)
